{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# heart_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.184378102316643e-07\n",
      "Fold number:  1\n",
      "the final training loss:  0.3699776389344176\n",
      "Accuracy:  0.819672131147541\n",
      "-3.053689309195917e-07\n",
      "Fold number:  2\n",
      "the final training loss:  0.36668635814619704\n",
      "Accuracy:  0.8032786885245902\n",
      "-3.0502281589406266e-07\n",
      "Fold number:  3\n",
      "the final training loss:  0.39198968249720695\n",
      "Accuracy:  0.8524590163934426\n",
      "-2.867195957323432e-07\n",
      "Fold number:  4\n",
      "the final training loss:  0.39228755533070425\n",
      "Accuracy:  0.8360655737704918\n",
      "-3.250911780328103e-07\n",
      "Fold number:  5\n",
      "the final training loss:  0.380567512475827\n",
      "Accuracy:  0.7868852459016393\n",
      "The average accuracy:  0.8196721311475409\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "The average accuracy:  0.8196721311475409\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "the final training loss:  5748300836.287946\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Read from file and load data in a list\n",
    "\n",
    "input: File input\n",
    "output: return a list which contain all data in the file\n",
    "\n",
    "Author: Waleed Khalid Bin Salman.\n",
    "version 1.00 11/10/2020\n",
    "\"\"\"\n",
    "def loadDataset(File_input):\n",
    "    with open(File_input) as csvfile:\n",
    "        lines = csv.reader(csvfile)\n",
    "        next(lines)\n",
    "        \n",
    "        return list(lines)\n",
    "\n",
    "    \n",
    "    \n",
    "\"\"\"\n",
    "shaffle the data inside a list\n",
    "\n",
    "input: list\n",
    "output: return a shuffled list \n",
    "\n",
    "Author: Waleed Khalid Bin Salman.\n",
    "version 1.00 26/9/2020\n",
    "\"\"\"    \n",
    "\n",
    "def shuffle_data(data):\n",
    "    shuffled_data=random.sample(data,len(data))\n",
    "    \n",
    "    return shuffled_data\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "split the data list with a specific percent \n",
    "\n",
    "input: list, split percent\n",
    "output: return a splited list \n",
    "\n",
    "Author: Waleed Khalid Bin Salman.\n",
    "version 1.00 26/9/2020\n",
    "\"\"\"   \n",
    "def split_data(shuffled_data,persent_of_test):\n",
    "    split = [shuffled_data[x:x+int((len(shuffled_data)*(persent_of_test/100)))] for x in range(0, len(shuffled_data), int((len(shuffled_data)*(persent_of_test/100))))]\n",
    "    \n",
    "    return split\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "predict a label given values of theta and features\n",
    "\n",
    "input: theta(can be any number), trainX (our features)\n",
    "output: return a list which contain all predict labels\n",
    "\n",
    "Author: Waleed Khalid Bin Salman.\n",
    "version 1.00 11/10/2020\n",
    "\"\"\"    \n",
    "def y_predict(theta, trainX):\n",
    "    y= np.dot(theta,trainX)\n",
    "    return 1/(1+np.exp(-y))\n",
    "\n",
    "\"\"\"\n",
    "group a split data into a train and test data\n",
    "\n",
    "input: list\n",
    "output: return list with groups of train and test data\n",
    "\n",
    "Author: Waleed Khalid Bin Salman.\n",
    "version 1.00 26/9/2020\n",
    "\"\"\"   \n",
    "def Train_Test_data(divided_data):\n",
    "    Test_data1= divided_data[0]+[divided_data[5][0]]\n",
    "    Train_data1=divided_data[1]+divided_data[2]+divided_data[3]+divided_data[4]+[divided_data[5][1]]+[divided_data[5][2]]\n",
    "    ######################################\n",
    "    Test_data2=divided_data[1]+[divided_data[5][0]]\n",
    "    Train_data2=divided_data[0]+divided_data[2]+divided_data[3]+divided_data[4]+[divided_data[5][1]]+[divided_data[5][2]]\n",
    "    ######################################\n",
    "    Test_data3=divided_data[2]+[divided_data[5][0]]\n",
    "    Train_data3=divided_data[0]+divided_data[1]+divided_data[3]+divided_data[4]+[divided_data[5][1]]+[divided_data[5][2]]\n",
    "    ######################################\n",
    "    Test_data4=divided_data[3]+[divided_data[5][0]]\n",
    "    Train_data4=divided_data[0]+divided_data[1]+divided_data[2]+divided_data[4]+[divided_data[5][1]]+[divided_data[5][2]]\n",
    "    ######################################\n",
    "    Test_data5=divided_data[4]+[divided_data[5][0]]\n",
    "    Train_data5=divided_data[0]+divided_data[1]+divided_data[2]+divided_data[3]+[divided_data[5][1]]+[divided_data[5][2]]\n",
    "    ######################################\n",
    "    Train_Test_data_list=[[Test_data1,Train_data1],[Test_data2,Train_data2],\n",
    "                          [Test_data3,Train_data3],[Test_data4,Train_data4],\n",
    "                          [Test_data5,Train_data5]]\n",
    "    \n",
    "    return Train_Test_data_list\n",
    "\n",
    "\"\"\"\n",
    "calculate the error between the true label and predicted label using MSE method\n",
    "\n",
    "input: true labels, predicted labels \n",
    "output: return the total value of error\n",
    "\n",
    "Author: Waleed Khalid Bin Salman.\n",
    "version 1.00 11/10/2020\n",
    "\"\"\"\n",
    "def MSE(y_true, y_predict):\n",
    "    return np.sum(np.power((y_true-y_predict),2))/len(y_true)\n",
    "\n",
    "\n",
    "\n",
    "def cross_entropy(y_true,y_predict):\n",
    "    #print(y_true)\n",
    "    return np.sum(((y_true)*(np.log(y_predict)))+((1-y_true)*(np.log(1-y_predict))))/(len(y_true)*-1)\n",
    "\"\"\"\n",
    "normlize our features\n",
    "\n",
    "input: features\n",
    "output: normlized features\n",
    "\n",
    "Author: Waleed Khalid Bin Salman.\n",
    "version 1.00 11/10/2020\n",
    "\"\"\"\n",
    "def normlize(feature, max_value):\n",
    "\n",
    "    \n",
    "    return np.array(feature)/max_value\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "traing our data to draw our best line.\n",
    "\n",
    "input: training data, learning_rate, limit_changing(between last two losses)\n",
    "\n",
    "Author: Waleed Khalid Bin Salman.\n",
    "version 1.00 11/10/2020\n",
    "\"\"\"\n",
    "data= loadDataset('heart.csv')\n",
    "Shuffled_DataSet= shuffle_data(data)\n",
    "Splited_Shuffled_DataSet= split_data(Shuffled_DataSet,20)\n",
    "list_Train_Test_DataSet= Train_Test_data(Splited_Shuffled_DataSet)\n",
    "fold=1\n",
    "accuracy=[]\n",
    "for group in list_Train_Test_DataSet:\n",
    "    Train_data= group[1]\n",
    "    Train_data_nu= np.array(Train_data)\n",
    "    Test_data= group[0]\n",
    "    Test_data_nu= np.array(Test_data)\n",
    "    \n",
    "    feature1= np.array(Train_data_nu[:,0],dtype=float)\n",
    "    max_value_feature1= max(feature1)\n",
    "    normlize_feature1= normlize(feature1,max_value_feature1)\n",
    "    \n",
    "    feature2= np.array(Train_data_nu[:,1],dtype=float)\n",
    "    max_value_feature2= max(feature2)\n",
    "    normlize_feature2= normlize(feature2,max_value_feature2)\n",
    "    \n",
    "    feature3= np.array(Train_data_nu[:,2],dtype=float)\n",
    "    max_value_feature3= max(feature3)\n",
    "    normlize_feature3= normlize(feature3,max_value_feature3)\n",
    "    \n",
    "    feature4= np.array(Train_data_nu[:,3],dtype=float)\n",
    "    max_value_feature4= max(feature4)\n",
    "    normlize_feature4= normlize(feature4,max_value_feature4)\n",
    "    \n",
    "    feature5= np.array(Train_data_nu[:,4],dtype=float)\n",
    "    max_value_feature5= max(feature5)\n",
    "    normlize_feature5= normlize(feature5,max_value_feature5)\n",
    "    \n",
    "    feature6= np.array(Train_data_nu[:,5],dtype=float)\n",
    "    max_value_feature6= max(feature6)\n",
    "    normlize_feature6= normlize(feature6,max_value_feature6)\n",
    "    \n",
    "    feature7= np.array(Train_data_nu[:,6],dtype=float)\n",
    "    max_value_feature7= max(feature7)\n",
    "    normlize_feature7= normlize(feature7,max_value_feature7)\n",
    "    \n",
    "    feature8= np.array(Train_data_nu[:,7],dtype=float)\n",
    "    max_value_feature8= max(feature8)\n",
    "    normlize_feature8= normlize(feature8,max_value_feature8)\n",
    "    \n",
    "    feature9= np.array(Train_data_nu[:,8],dtype=float)\n",
    "    max_value_feature9= max(feature9)\n",
    "    normlize_feature9= normlize(feature9,max_value_feature9)\n",
    "    \n",
    "    feature10= np.array(Train_data_nu[:,9],dtype=float)\n",
    "    max_value_feature10= max(feature10)\n",
    "    normlize_feature10= normlize(feature10,max_value_feature10)\n",
    "    \n",
    "    feature11= np.array(Train_data_nu[:,10],dtype=float)\n",
    "    max_value_feature11= max(feature11)\n",
    "    normlize_feature11= normlize(feature11,max_value_feature11)\n",
    "    \n",
    "    feature12= np.array(Train_data_nu[:,11],dtype=float)\n",
    "    max_value_feature12= max(feature12)\n",
    "    normlize_feature12= normlize(feature12,max_value_feature12)\n",
    "    \n",
    "    feature13= np.array(Train_data_nu[:,12],dtype=float)\n",
    "    max_value_feature13= max(feature13)\n",
    "    normlize_feature13= normlize(feature13,max_value_feature13)\n",
    "    \n",
    "    ones= np.ones((len(feature1)),dtype=float)\n",
    "\n",
    "    train_features= np.array([ones,normlize_feature1,normlize_feature2,normlize_feature3,\n",
    "                              normlize_feature4,normlize_feature5,normlize_feature6,\n",
    "                              normlize_feature7,normlize_feature8,normlize_feature9,\n",
    "                              normlize_feature10,normlize_feature11,normlize_feature12,\n",
    "                              normlize_feature13],dtype=float)\n",
    "    \n",
    "    train_labels= np.array(Train_data_nu[:,-1],dtype=float)\n",
    "\n",
    "    theta= np.zeros((14),dtype=float)\n",
    "    \n",
    "    loss=[]\n",
    "    lr= 0.001\n",
    "    lm= 10**-4\n",
    "    diff_loss= float(\"inf\")\n",
    "    #itteration\n",
    "    for _ in range(100000):#while (diff_loss > lm):\n",
    "        y_pre=y_predict(theta, train_features) \n",
    "        Grad= train_features.dot((y_pre-train_labels).transpose()) / len(train_labels)\n",
    "        loss.append(cross_entropy(train_labels,y_pre))\n",
    "        theta= theta - lr*Grad.transpose()\n",
    "        \n",
    "        if(len(loss) >= 2):\n",
    "            diff_loss = abs(loss[-1] - loss[-2])\n",
    "    \n",
    "    print(loss[-1] - loss[-2])\n",
    "    print('Fold number: ', fold)\n",
    "    fold= fold+1\n",
    "    print(\"the final training loss: \", str(loss[-1]))\n",
    "    \n",
    "    \n",
    "    feature1= np.array(Test_data_nu[:,0],dtype=float)\n",
    "    normlize_feature1= normlize(feature1,max_value_feature1)\n",
    "    \n",
    "    feature2= np.array(Test_data_nu[:,1],dtype=float)\n",
    "    normlize_feature2= normlize(feature2,max_value_feature2)\n",
    "    \n",
    "    feature3= np.array(Test_data_nu[:,2],dtype=float)\n",
    "    normlize_feature3= normlize(feature3,max_value_feature3)\n",
    "    \n",
    "    feature4= np.array(Test_data_nu[:,3],dtype=float)\n",
    "    normlize_feature4= normlize(feature4,max_value_feature4)\n",
    "    \n",
    "    feature5= np.array(Test_data_nu[:,4],dtype=float)\n",
    "    normlize_feature5= normlize(feature5,max_value_feature5)\n",
    "    \n",
    "    feature6= np.array(Test_data_nu[:,5],dtype=float)\n",
    "    normlize_feature6= normlize(feature6,max_value_feature6)\n",
    "    \n",
    "    feature7= np.array(Test_data_nu[:,6],dtype=float)\n",
    "    normlize_feature7= normlize(feature7,max_value_feature7)\n",
    "    \n",
    "    feature8= np.array(Test_data_nu[:,7],dtype=float)\n",
    "    normlize_feature8= normlize(feature8,max_value_feature8)\n",
    "    \n",
    "    feature9= np.array(Test_data_nu[:,8],dtype=float)\n",
    "    normlize_feature9= normlize(feature9,max_value_feature9)\n",
    "    \n",
    "    feature10= np.array(Test_data_nu[:,9],dtype=float)\n",
    "    normlize_feature10= normlize(feature10,max_value_feature10)\n",
    "    \n",
    "    feature11= np.array(Test_data_nu[:,10],dtype=float)\n",
    "    normlize_feature11= normlize(feature11,max_value_feature11)\n",
    "    \n",
    "    feature12= np.array(Test_data_nu[:,11],dtype=float)\n",
    "    normlize_feature12= normlize(feature12,max_value_feature12)\n",
    "    \n",
    "    feature13= np.array(Test_data_nu[:,12],dtype=float)\n",
    "    normlize_feature13= normlize(feature13,max_value_feature13)\n",
    "    \n",
    "    ones= np.ones((len(feature1)),dtype=float)\n",
    "\n",
    "    train_features= np.array([ones,normlize_feature1,normlize_feature2,normlize_feature3,\n",
    "                              normlize_feature4,normlize_feature5,normlize_feature6,\n",
    "                              normlize_feature7,normlize_feature8,normlize_feature9,\n",
    "                              normlize_feature10,normlize_feature11,normlize_feature12,\n",
    "                              normlize_feature13],dtype=float)\n",
    "    \n",
    "    train_labels= np.array(Test_data_nu[:,-1],dtype=float)\n",
    "    \n",
    "    #print('theta',theta)\n",
    "    y_pre_test =y_predict(theta, train_features)\n",
    "    accuracy.append(np.sum(train_labels == np.round(y_pre_test))/len(train_labels))\n",
    "    print('Accuracy: ',np.sum(train_labels == np.round(y_pre_test))/len(train_labels))\n",
    "\n",
    "    \n",
    "\n",
    "print('The average accuracy: ',(sum(accuracy)/len(accuracy)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART_2_IRIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "the average accuracy:  0.8600000000000001\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def LR(iteration,lr,train_features,train_labels):\n",
    "    theta= np.zeros((1,train_features.shape[0]))\n",
    "    loss=[]\n",
    "    lr= lr\n",
    "    lm= 10**-4\n",
    "    diff_loss= float(\"inf\")\n",
    "    #itteration\n",
    "    for _ in range(iteration):#while (diff_loss > lm):\n",
    "        y_pre=y_predict(theta, train_features) \n",
    "        Grad= train_features.dot((y_pre-train_labels).transpose()) / len(train_labels)\n",
    "        loss.append(cross_entropy(train_labels,y_pre))\n",
    "        theta= theta - lr*Grad.transpose()\n",
    "                    \n",
    "    return theta,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_accuracy(List,df):\n",
    "    \n",
    "    correct = []\n",
    "\n",
    "    for n,i in enumerate(List[0]):\n",
    "        encoding = df.iloc[:,-3:].iloc[n]\n",
    "\n",
    "        \n",
    "        if(i == 0 and encoding[0] == 1):\n",
    "            correct.append(1)\n",
    "        elif(i == 2 and encoding[1] == 1):\n",
    "            correct.append(1)\n",
    "        elif(i == 1 and encoding[2] == 1):\n",
    "            correct.append(1)\n",
    "        else:\n",
    "            correct.append(0)\n",
    "            \n",
    "            \n",
    "    return sum(correct)/len(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(theta1,theta2,theta3,test):\n",
    "    \n",
    "    y1 = np.exp(theta1.dot(test)) / (np.exp(theta1.dot(test)) + np.exp(theta2.dot(test)) + np.exp(theta3.dot(test)))\n",
    "    y2 = np.exp(theta2.dot(test)) / (np.exp(theta1.dot(test)) + np.exp(theta2.dot(test)) + np.exp(theta3.dot(test)))\n",
    "    y3 = np.exp(theta3.dot(test)) / (np.exp(theta1.dot(test)) + np.exp(theta2.dot(test)) + np.exp(theta3.dot(test)))\n",
    "    \n",
    "    return np.argmax(np.array([y1,y2,y3]),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>0.632911</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>0.607595</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "60   0.406667       0.632911      0.454545       0.507246          0.40   \n",
       "132  0.886667       0.810127      0.636364       0.811594          0.88   \n",
       "124  0.833333       0.848101      0.750000       0.826087          0.84   \n",
       "20   0.140000       0.683544      0.772727       0.246377          0.08   \n",
       "12   0.086667       0.607595      0.681818       0.202899          0.04   \n",
       "\n",
       "     Iris-setosa  Iris-versicolor  Iris-virginica  \n",
       "60             0                1               0  \n",
       "132            0                0               1  \n",
       "124            0                0               1  \n",
       "20             1                0               0  \n",
       "12             1                0               0  "
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df= pd.read_csv('Iris.csv')\n",
    "#data.Species.unique()\n",
    "df['Iris-setosa']=(df['Species']=='Iris-setosa').astype(int)\n",
    "df['Iris-versicolor']=(df['Species']=='Iris-versicolor').astype(int)\n",
    "df['Iris-virginica']=(df['Species']=='Iris-virginica').astype(int)\n",
    "del df['Species']\n",
    "\n",
    "df= df.reindex(np.random.permutation(df.index))\n",
    "\n",
    "\n",
    "for f in df.columns[:-3]:\n",
    "    df[f]= df[f]/df[f].max()\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Iris-setosa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.632911</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.507246</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>0.810127</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.811594</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.848101</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.683544</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.246377</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.607595</td>\n",
       "      <td>0.681818</td>\n",
       "      <td>0.202899</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Iris-setosa\n",
       "60        0.632911      0.454545       0.507246          0.40            0\n",
       "132       0.810127      0.636364       0.811594          0.88            0\n",
       "124       0.848101      0.750000       0.826087          0.84            0\n",
       "20        0.683544      0.772727       0.246377          0.08            1\n",
       "12        0.607595      0.681818       0.202899          0.04            1"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_setosa=df.drop(columns=['Id','Iris-versicolor','Iris-virginica'])\n",
    "df_versicolor=df.drop(columns=['Id','Iris-setosa','Iris-virginica'])\n",
    "df_virginica= df.drop(columns=['Id','Iris-versicolor','Iris-setosa'])\n",
    "\n",
    "df_setosa.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_setosa =    np.array_split(df_setosa, 5)\n",
    "df_versicolor= np.array_split(df_versicolor, 5)\n",
    "df_virginica=  np.array_split(df_virginica, 5)\n",
    "dfs = np.array_split(df,5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Fold Number 1\n",
      "  Iris-setosa vs other classes\n",
      "   Accuracy: 0.4666666666666667\n",
      "  Iris-virginica vs other classes\n",
      "   Accuracy: 0.9333333333333333\n",
      "  Iris-versicolor vs other classes\n",
      "   Accuracy: 0.6333333333333333\n",
      "taking max Accuracy : 0.6666666666666666\n",
      "\n",
      "the average accuracy:  0.6666666666666666\n",
      "--------------------------------------------------\n",
      "Fold Number 2\n",
      "  Iris-setosa vs other classes\n",
      "   Accuracy: 0.26666666666666666\n",
      "  Iris-virginica vs other classes\n",
      "   Accuracy: 0.9666666666666667\n",
      "  Iris-versicolor vs other classes\n",
      "   Accuracy: 0.6666666666666666\n",
      "taking max Accuracy : 0.9666666666666667\n",
      "\n",
      "the average accuracy:  0.8166666666666667\n",
      "--------------------------------------------------\n",
      "Fold Number 3\n",
      "  Iris-setosa vs other classes\n",
      "   Accuracy: 0.4666666666666667\n",
      "  Iris-virginica vs other classes\n",
      "   Accuracy: 1.0\n",
      "  Iris-versicolor vs other classes\n",
      "   Accuracy: 0.6333333333333333\n",
      "taking max Accuracy : 0.8\n",
      "\n",
      "the average accuracy:  0.8111111111111112\n",
      "--------------------------------------------------\n",
      "Fold Number 4\n",
      "  Iris-setosa vs other classes\n",
      "   Accuracy: 0.2\n",
      "  Iris-virginica vs other classes\n",
      "   Accuracy: 0.9333333333333333\n",
      "  Iris-versicolor vs other classes\n",
      "   Accuracy: 0.6333333333333333\n",
      "taking max Accuracy : 0.9666666666666667\n",
      "\n",
      "the average accuracy:  0.8500000000000001\n",
      "--------------------------------------------------\n",
      "Fold Number 5\n",
      "  Iris-setosa vs other classes\n",
      "   Accuracy: 0.26666666666666666\n",
      "  Iris-virginica vs other classes\n",
      "   Accuracy: 1.0\n",
      "  Iris-versicolor vs other classes\n",
      "   Accuracy: 0.7\n",
      "taking max Accuracy : 0.9\n",
      "\n",
      "the average accuracy:  0.8600000000000001\n"
     ]
    }
   ],
   "source": [
    "a1 = 0\n",
    "a2 = 0\n",
    "a3 = 0\n",
    "\n",
    "accuracy=[]\n",
    "for x in range(len(df_setosa)):\n",
    "    \n",
    "    fold1    = df_setosa[x].values.T[:-1]\n",
    "    len1     = fold1.shape[1]\n",
    "    test_x1  = np.vstack((np.ones(len1), fold1))\n",
    "    test_y1  = df_setosa[x].values.T[-1]\n",
    "    train_x1 = pd.concat(df_setosa[:x] + df_setosa[x+1:]).values.T[:-1]\n",
    "    train_x1 = np.vstack((np.ones(train_x1.shape[1]),train_x1))\n",
    "    train_y1 = pd.concat(df_setosa[:x] + df_setosa[x+1:]).values.T[-1]\n",
    "    \n",
    "    fold2    = df_virginica[x].values.T[:-1]\n",
    "    len2     = fold2.shape[1]\n",
    "    test_x2  = np.vstack((np.ones(len2), fold2))\n",
    "    test_y2  = df_virginica[x].values.T[-1]\n",
    "    train_x2 = pd.concat(df_virginica[:x] + df_virginica[x+1:]).values.T[:-1]\n",
    "    train_x2 = np.vstack((np.ones(train_x2.shape[1]),train_x2))\n",
    "    train_y2 = pd.concat(df_virginica[:x] + df_virginica[x+1:]).values.T[-1]\n",
    "    \n",
    "    fold3    = df_versicolor[x].values.T[:-1]\n",
    "    len3     = fold3.shape[1]\n",
    "    test_x3  = np.vstack((np.ones(len3), fold3))\n",
    "    test_y3  = df_versicolor[x].values.T[-1]\n",
    "    train_x3 = pd.concat(df_versicolor[:x] + df_versicolor[x+1:]).values.T[:-1]\n",
    "    train_x3 = np.vstack((np.ones(train_x3.shape[1]),train_x3))\n",
    "    train_y3 = pd.concat(df_versicolor[:x] + df_versicolor[x+1:]).values.T[-1]\n",
    "    \n",
    "    print('--------------------------------------------------')\n",
    "    print(f'Fold Number {x+1}')\n",
    "    print(f'  Iris-setosa vs other classes')\n",
    "    theta1,loss1 = LR(100000,0.001,train_x1,train_y1)\n",
    "#     print(theta1)\n",
    "#     print('---------------------')\n",
    "#     print(test_x1)\n",
    "    y_pred1 = y_predict(theta1, test_x1)\n",
    "    y_pred1 = 1/(1 + np.exp(-y_pred1))\n",
    "    Acc1 = (np.sum(test_y1 == np.round(y_pred1))/ len(test_y1))\n",
    "    print(f'   Accuracy: {Acc1}')\n",
    "#     print(theta1)\n",
    "    \n",
    "    if(Acc1 > a1):\n",
    "        thetaf1 = theta1\n",
    "        a1 = Acc1\n",
    "    print(f'  Iris-virginica vs other classes')\n",
    "    theta2,loss2 = LR(100000,0.001,train_x2,train_y2)\n",
    "    \n",
    "    y_pred2 = theta2.dot(test_x2)\n",
    "    y_pred2 = 1/(1 + np.exp(-y_pred2))\n",
    "    Acc2 = (np.sum(test_y2 == np.round(y_pred2))/ len(test_y2))\n",
    "    print(f'   Accuracy: {Acc2}')\n",
    "\n",
    "    \n",
    "    if(Acc2 > a2):\n",
    "        thetaf2 = theta2\n",
    "        a2 = Acc2\n",
    "    print(f'  Iris-versicolor vs other classes')\n",
    "    theta3,loss3 = LR(100000,0.001,train_x3,train_y3)\n",
    "    \n",
    "    y_pred3 = theta3.dot(test_x3)\n",
    "    y_pred3 = 1/(1 + np.exp(-y_pred3))\n",
    "    Acc3 = (np.sum(test_y3 == np.round(y_pred3))/ len(test_y3))\n",
    "    print(f'   Accuracy: {Acc3}')\n",
    "\n",
    "    \n",
    "    if(Acc3 > a3):\n",
    "        thetaf3 = theta3\n",
    "        a3 = Acc3\n",
    "        \n",
    "    c = softmax(theta1,theta2,theta3,test_x1)\n",
    "    accuracy.append(mean_accuracy(c,dfs[x].iloc[:,-3:]))\n",
    "    print(f'taking max Accuracy : {mean_accuracy(c,dfs[x].iloc[:,-3:])}')\n",
    "\n",
    "    \n",
    "    print()\n",
    "    print('the average accuracy: ', (sum(accuracy)/len(accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
